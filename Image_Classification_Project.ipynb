{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_homework1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyUJAJbuUyjA"
      },
      "source": [
        "#Table of content\n",
        "1.   Connect drive\n",
        "2.   Libraries\n",
        "3.   Prepare the training data\n",
        "4.   CNN the classical way\n",
        "  1.   Data augmentation\n",
        "  2.   Dealing with an imbalanced data\n",
        "  3.   In-House Neural Network\n",
        "5.   Transfer Learning\n",
        "  1.   Data preparation\n",
        "  1.   VGG16\n",
        "  2.   InceptionV3\n",
        "  3.   Inception model fine tuning : Final Model\n",
        "6.   Analysis of the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0B-FyIE3Lhq"
      },
      "source": [
        "## Connect drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh7nJkDf3rAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709fb017-2efa-4602-e0e9-ff82685d4281"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae-5gQN33uRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52113a6a-1269-46b8-be20-2918c83f8e6a"
      },
      "source": [
        "%cd /gdrive/MyDrive/AN2DL_Challenge1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/AN2DL_Challenge1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4dfivm83QYo"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWCzwOd3w9y"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xcu1US32rT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa5773a-c4cc-4b9e-8caf-a17cfc0aedef"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1riU11ay4Mq0"
      },
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XswyDerl35IT"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcQiaS-c35mi"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtYWWqG13TbT"
      },
      "source": [
        "## Prepare the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43TSySPQ4C8i"
      },
      "source": [
        "#!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIK81k4GQF"
      },
      "source": [
        "source = 'training'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jfxVuC34H7q"
      },
      "source": [
        "#the name of the classes\n",
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J-sRT6p7KDg"
      },
      "source": [
        "## CNN the classical way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXpfSXXx3XFK"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PxTnjIYYrXw"
      },
      "source": [
        "test_source = 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygDuS1oG4V3j"
      },
      "source": [
        "# ImageDataGenerator\n",
        "# ------------------\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "apply_data_augmentation = True  \n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "if apply_data_augmentation:\n",
        "    train_data_gen = ImageDataGenerator(\n",
        "                                        rotation_range=10,\n",
        "                                        width_shift_range=10,\n",
        "                                        height_shift_range=10,\n",
        "                                        zoom_range=0.3,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=False,\n",
        "                                        fill_mode='constant',\n",
        "                                        cval=0,\n",
        "                                        rescale=1./255,\n",
        "                                        preprocessing_function=None,\n",
        "                                        data_format='channels_last',\n",
        "                                        validation_split=0.2,    \n",
        "                                       )\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#here I create the validation data generator\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3aCS3a4ZsK"
      },
      "source": [
        "# Create generators to read images from dataset directory\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# Batch size\n",
        "bs = 32\n",
        "\n",
        "# Image shape\n",
        "img_h = 256   #height of the images\n",
        "img_w = 256   #width of the images\n",
        "\n",
        "num_classes = 14\n",
        "\n",
        "classes = labels\n",
        "\n",
        "#Training\n",
        "train_gen = train_data_gen.flow_from_directory(source,\n",
        "                                               batch_size=bs,\n",
        "                                               classes=classes,\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True, #it's nice to have them shuffled\n",
        "                                               subset='training',\n",
        "                                               seed=seed)  \n",
        "\n",
        "# Validation \n",
        "valid_gen = valid_data_gen.flow_from_directory(source,\n",
        "                                                batch_size=bs,\n",
        "                                                classes=classes,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True, \n",
        "                                                subset='validation',\n",
        "                                                seed=seed)\n",
        "\n",
        "test_gen = test_data_gen.flow_from_directory(test_source, #different from the other\n",
        "                                                batch_size=1,\n",
        "                                                classes=classes,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=False, #to be able to print the confusion matrix \n",
        "                                                subset='training',\n",
        "                                                seed=seed) # set as validation data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqrcrRbh63ZW"
      },
      "source": [
        "### Dealing with an imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dNDcSAUVTfj"
      },
      "source": [
        "# Compute the class weights in order to balance loss during training\n",
        "counter = Counter(train_gen.classes)                          \n",
        "max_val = float(max(counter.values()))       \n",
        "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
        "print(class_weights)\n",
        "\n",
        "# This will help, conjugated with a slight oversampling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr122hv0X8iZ"
      },
      "source": [
        "### In-House Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHek69d7QUu"
      },
      "source": [
        "input_shape = (256, 256, 3)\n",
        "epochs = 200\n",
        "\n",
        "def build_model(input_shape):\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    resizing_layer = tfkl.Resizing(64, 64, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(input_layer)\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        #kernel_regularizer = 'l2'\n",
        "    )(resizing_layer)\n",
        "\n",
        "    bn_layer1 = tfkl.BatchNormalization()(conv1)\n",
        "\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(bn_layer1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        #kernel_regularizer = 'l2'\n",
        "    )(pool1)\n",
        "\n",
        "    bn_layer2 = tfkl.BatchNormalization()(conv2)\n",
        "\n",
        "\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(bn_layer2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        #kernel_regularizer = 'l2'\n",
        "    )(pool2)\n",
        "\n",
        "    bn_layer3 = tfkl.BatchNormalization()(conv3)\n",
        "\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(bn_layer3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        #kernel_regularizer = 'l2'\n",
        "    )(pool3)\n",
        "\n",
        "    bn_layer4 = tfkl.BatchNormalization()(conv4)\n",
        "\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(bn_layer4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        #kernel_regularizer = 'l2'\n",
        "    )(pool4)\n",
        "\n",
        "    bn_layer5 = tfkl.BatchNormalization()(conv5)\n",
        "\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(bn_layer5)\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    flattening_layer = tfkl.Dropout(0.30, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=512, name='Classifier', activation='relu')(flattening_layer)\n",
        "    classifier_layer = tfkl.Dropout(0.30, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=14, activation='softmax', name='Output')(classifier_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCPFajBY7Zsr"
      },
      "source": [
        "model = build_model(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PLjgRBl7dZz"
      },
      "source": [
        "patience = 15\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=patience, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = train_gen,\n",
        "    validation_data = valid_gen,\n",
        "    epochs = 250,\n",
        "    shuffle = True,\n",
        "    class_weight = class_weights,\n",
        "    callbacks = [early_stopping]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChFLADU57mHs"
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "# Save model, with the date in its name for no confusion\n",
        "model.save(\"model_saved_\" + now)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt6qnh5E7qWg"
      },
      "source": [
        "#In case we want to continue the training of an old model\n",
        "#model = tfk.models.load_model('D:/ANNDL/model_saved_Nov25_10-01-50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK5EaZ92VFI3"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw0sIUEwYXD_"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprGD2gWYSX6"
      },
      "source": [
        "# ImageDataGenerator\n",
        "\n",
        "apply_data_augmentation = True  \n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "if apply_data_augmentation:\n",
        "    train_data_gen = ImageDataGenerator(\n",
        "                                        rotation_range=10,\n",
        "                                        width_shift_range=10,\n",
        "                                        height_shift_range=10,\n",
        "                                        zoom_range=0.3,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=False,\n",
        "                                        fill_mode='constant',\n",
        "                                        cval=0,\n",
        "                                        rescale=1./255,\n",
        "                                        preprocessing_function=None,\n",
        "                                        data_format='channels_last',\n",
        "                                        validation_split=0.2,    \n",
        "                                       )\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Create the validation data generator\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLfedfTqZaQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d245712-7bc9-47a7-f31e-1303d47178cc"
      },
      "source": [
        "# Batch size\n",
        "bs = 32\n",
        "\n",
        "# Image shape\n",
        "img_h = 256   #height\n",
        "img_w = 256   #width\n",
        "\n",
        "num_classes = 14\n",
        "\n",
        "classes = labels\n",
        "\n",
        "#Training\n",
        "train_gen = train_data_gen.flow_from_directory(source,\n",
        "                                               batch_size=bs,\n",
        "                                               classes=classes,\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True, #it's nice to have them shuffled\n",
        "                                               subset='training',\n",
        "                                               seed=seed)  \n",
        "\n",
        "# Validation \n",
        "valid_gen = valid_data_gen.flow_from_directory(source,\n",
        "                                                batch_size=bs,\n",
        "                                                classes=classes,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True, \n",
        "                                                subset='validation',\n",
        "                                                seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14189 images belonging to 14 classes.\n",
            "Found 3539 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRFN8bJYVV63"
      },
      "source": [
        "# Create Dataset objects\n",
        "# ----------------------\n",
        "\n",
        "# Training\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation\n",
        "# ----------\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRlBv6CDb8zP"
      },
      "source": [
        "# Compute the class weights\n",
        "counter = Counter(train_gen.classes)                          \n",
        "max_val = float(max(counter.values()))       \n",
        "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLw99wue1EP3"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUVWfIz81H7R"
      },
      "source": [
        "# VGG16\n",
        "Vgg16 = tf.keras.applications.VGG16(weights='imagenet', \n",
        "                                include_top=False, \n",
        "                                input_shape=(img_h, img_w,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGapv90f1etX"
      },
      "source": [
        "# model for Transfer Learning done with VGG16\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(Vgg16)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pnGEEvt1hVb"
      },
      "source": [
        "# Loss\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# learning rate\n",
        "lr = 2e-5\n",
        "#optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# Validation metrics\n",
        "metrics = ['accuracy']\n",
        "#callbacks\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANiRtaOcZ3av"
      },
      "source": [
        "# I usually stop the training manually because I don't want colab to crash and lose everything\n",
        "model.fit(x=train_dataset,\n",
        "          epochs=30,\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen),\n",
        "          class_weight=class_weights,\n",
        "          callbacks = es_callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfbW95tc1ljV"
      },
      "source": [
        "model.save(\"classification_experiments/vggattempt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8_hT00O3f9h"
      },
      "source": [
        "### InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te2jx1lLVaeW"
      },
      "source": [
        "# InceptionV3\n",
        "inception = tf.keras.applications.InceptionV3(weights='imagenet', \n",
        "                                include_top=False, \n",
        "                                input_shape=(img_h, img_w,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQIAh8ZRJqic"
      },
      "source": [
        "# model for Transfer Learning done with Inception\n",
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(inception)\n",
        "model1.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model1.add(tf.keras.layers.Dropout(0.3))\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model1.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3xhOf7GV8y2"
      },
      "source": [
        "# Loss\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# learning rate\n",
        "lr = 2e-5\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# -------------------\n",
        "\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "\n",
        "metrics = ['accuracy']\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "#callbacks\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6NDHa1KZlT"
      },
      "source": [
        "hist1 = model1.fit(x=train_dataset,\n",
        "          epochs=30,\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen),\n",
        "          class_weight=class_weights,callbacks = es_callback).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlJKC85EWDiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac0a523-b203-4e03-ebeb-102bc5e72474"
      },
      "source": [
        "model1.save(\"classification_experiments/inceptionattempt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: classification_experiments/inceptionattempt/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7kvafzNbU8t"
      },
      "source": [
        "### Inception model fine tuning : Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvBFA7Sg9Zkl"
      },
      "source": [
        "del model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj-6_sueJz1u"
      },
      "source": [
        "# Re-load the model after transfer learning\n",
        "ft_model = tfk.models.load_model('classification_experiments/inceptionattempt')\n",
        "ft_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr9X5GU_HfSh",
        "outputId": "6b85986c-5756-4862-ef96-d8cceb1aa08e"
      },
      "source": [
        "# Set all Inception layers to True\n",
        "ft_model.get_layer('inception_v3').trainable = True\n",
        "for i, layer in enumerate(ft_model.get_layer('inception_v3').layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 True\n",
            "1 conv2d True\n",
            "2 batch_normalization True\n",
            "3 activation True\n",
            "4 conv2d_1 True\n",
            "5 batch_normalization_1 True\n",
            "6 activation_1 True\n",
            "7 conv2d_2 True\n",
            "8 batch_normalization_2 True\n",
            "9 activation_2 True\n",
            "10 max_pooling2d True\n",
            "11 conv2d_3 True\n",
            "12 batch_normalization_3 True\n",
            "13 activation_3 True\n",
            "14 conv2d_4 True\n",
            "15 batch_normalization_4 True\n",
            "16 activation_4 True\n",
            "17 max_pooling2d_1 True\n",
            "18 conv2d_8 True\n",
            "19 batch_normalization_8 True\n",
            "20 activation_8 True\n",
            "21 conv2d_6 True\n",
            "22 conv2d_9 True\n",
            "23 batch_normalization_6 True\n",
            "24 batch_normalization_9 True\n",
            "25 activation_6 True\n",
            "26 activation_9 True\n",
            "27 average_pooling2d True\n",
            "28 conv2d_5 True\n",
            "29 conv2d_7 True\n",
            "30 conv2d_10 True\n",
            "31 conv2d_11 True\n",
            "32 batch_normalization_5 True\n",
            "33 batch_normalization_7 True\n",
            "34 batch_normalization_10 True\n",
            "35 batch_normalization_11 True\n",
            "36 activation_5 True\n",
            "37 activation_7 True\n",
            "38 activation_10 True\n",
            "39 activation_11 True\n",
            "40 mixed0 True\n",
            "41 conv2d_15 True\n",
            "42 batch_normalization_15 True\n",
            "43 activation_15 True\n",
            "44 conv2d_13 True\n",
            "45 conv2d_16 True\n",
            "46 batch_normalization_13 True\n",
            "47 batch_normalization_16 True\n",
            "48 activation_13 True\n",
            "49 activation_16 True\n",
            "50 average_pooling2d_1 True\n",
            "51 conv2d_12 True\n",
            "52 conv2d_14 True\n",
            "53 conv2d_17 True\n",
            "54 conv2d_18 True\n",
            "55 batch_normalization_12 True\n",
            "56 batch_normalization_14 True\n",
            "57 batch_normalization_17 True\n",
            "58 batch_normalization_18 True\n",
            "59 activation_12 True\n",
            "60 activation_14 True\n",
            "61 activation_17 True\n",
            "62 activation_18 True\n",
            "63 mixed1 True\n",
            "64 conv2d_22 True\n",
            "65 batch_normalization_22 True\n",
            "66 activation_22 True\n",
            "67 conv2d_20 True\n",
            "68 conv2d_23 True\n",
            "69 batch_normalization_20 True\n",
            "70 batch_normalization_23 True\n",
            "71 activation_20 True\n",
            "72 activation_23 True\n",
            "73 average_pooling2d_2 True\n",
            "74 conv2d_19 True\n",
            "75 conv2d_21 True\n",
            "76 conv2d_24 True\n",
            "77 conv2d_25 True\n",
            "78 batch_normalization_19 True\n",
            "79 batch_normalization_21 True\n",
            "80 batch_normalization_24 True\n",
            "81 batch_normalization_25 True\n",
            "82 activation_19 True\n",
            "83 activation_21 True\n",
            "84 activation_24 True\n",
            "85 activation_25 True\n",
            "86 mixed2 True\n",
            "87 conv2d_27 True\n",
            "88 batch_normalization_27 True\n",
            "89 activation_27 True\n",
            "90 conv2d_28 True\n",
            "91 batch_normalization_28 True\n",
            "92 activation_28 True\n",
            "93 conv2d_26 True\n",
            "94 conv2d_29 True\n",
            "95 batch_normalization_26 True\n",
            "96 batch_normalization_29 True\n",
            "97 activation_26 True\n",
            "98 activation_29 True\n",
            "99 max_pooling2d_2 True\n",
            "100 mixed3 True\n",
            "101 conv2d_34 True\n",
            "102 batch_normalization_34 True\n",
            "103 activation_34 True\n",
            "104 conv2d_35 True\n",
            "105 batch_normalization_35 True\n",
            "106 activation_35 True\n",
            "107 conv2d_31 True\n",
            "108 conv2d_36 True\n",
            "109 batch_normalization_31 True\n",
            "110 batch_normalization_36 True\n",
            "111 activation_31 True\n",
            "112 activation_36 True\n",
            "113 conv2d_32 True\n",
            "114 conv2d_37 True\n",
            "115 batch_normalization_32 True\n",
            "116 batch_normalization_37 True\n",
            "117 activation_32 True\n",
            "118 activation_37 True\n",
            "119 average_pooling2d_3 True\n",
            "120 conv2d_30 True\n",
            "121 conv2d_33 True\n",
            "122 conv2d_38 True\n",
            "123 conv2d_39 True\n",
            "124 batch_normalization_30 True\n",
            "125 batch_normalization_33 True\n",
            "126 batch_normalization_38 True\n",
            "127 batch_normalization_39 True\n",
            "128 activation_30 True\n",
            "129 activation_33 True\n",
            "130 activation_38 True\n",
            "131 activation_39 True\n",
            "132 mixed4 True\n",
            "133 conv2d_44 True\n",
            "134 batch_normalization_44 True\n",
            "135 activation_44 True\n",
            "136 conv2d_45 True\n",
            "137 batch_normalization_45 True\n",
            "138 activation_45 True\n",
            "139 conv2d_41 True\n",
            "140 conv2d_46 True\n",
            "141 batch_normalization_41 True\n",
            "142 batch_normalization_46 True\n",
            "143 activation_41 True\n",
            "144 activation_46 True\n",
            "145 conv2d_42 True\n",
            "146 conv2d_47 True\n",
            "147 batch_normalization_42 True\n",
            "148 batch_normalization_47 True\n",
            "149 activation_42 True\n",
            "150 activation_47 True\n",
            "151 average_pooling2d_4 True\n",
            "152 conv2d_40 True\n",
            "153 conv2d_43 True\n",
            "154 conv2d_48 True\n",
            "155 conv2d_49 True\n",
            "156 batch_normalization_40 True\n",
            "157 batch_normalization_43 True\n",
            "158 batch_normalization_48 True\n",
            "159 batch_normalization_49 True\n",
            "160 activation_40 True\n",
            "161 activation_43 True\n",
            "162 activation_48 True\n",
            "163 activation_49 True\n",
            "164 mixed5 True\n",
            "165 conv2d_54 True\n",
            "166 batch_normalization_54 True\n",
            "167 activation_54 True\n",
            "168 conv2d_55 True\n",
            "169 batch_normalization_55 True\n",
            "170 activation_55 True\n",
            "171 conv2d_51 True\n",
            "172 conv2d_56 True\n",
            "173 batch_normalization_51 True\n",
            "174 batch_normalization_56 True\n",
            "175 activation_51 True\n",
            "176 activation_56 True\n",
            "177 conv2d_52 True\n",
            "178 conv2d_57 True\n",
            "179 batch_normalization_52 True\n",
            "180 batch_normalization_57 True\n",
            "181 activation_52 True\n",
            "182 activation_57 True\n",
            "183 average_pooling2d_5 True\n",
            "184 conv2d_50 True\n",
            "185 conv2d_53 True\n",
            "186 conv2d_58 True\n",
            "187 conv2d_59 True\n",
            "188 batch_normalization_50 True\n",
            "189 batch_normalization_53 True\n",
            "190 batch_normalization_58 True\n",
            "191 batch_normalization_59 True\n",
            "192 activation_50 True\n",
            "193 activation_53 True\n",
            "194 activation_58 True\n",
            "195 activation_59 True\n",
            "196 mixed6 True\n",
            "197 conv2d_64 True\n",
            "198 batch_normalization_64 True\n",
            "199 activation_64 True\n",
            "200 conv2d_65 True\n",
            "201 batch_normalization_65 True\n",
            "202 activation_65 True\n",
            "203 conv2d_61 True\n",
            "204 conv2d_66 True\n",
            "205 batch_normalization_61 True\n",
            "206 batch_normalization_66 True\n",
            "207 activation_61 True\n",
            "208 activation_66 True\n",
            "209 conv2d_62 True\n",
            "210 conv2d_67 True\n",
            "211 batch_normalization_62 True\n",
            "212 batch_normalization_67 True\n",
            "213 activation_62 True\n",
            "214 activation_67 True\n",
            "215 average_pooling2d_6 True\n",
            "216 conv2d_60 True\n",
            "217 conv2d_63 True\n",
            "218 conv2d_68 True\n",
            "219 conv2d_69 True\n",
            "220 batch_normalization_60 True\n",
            "221 batch_normalization_63 True\n",
            "222 batch_normalization_68 True\n",
            "223 batch_normalization_69 True\n",
            "224 activation_60 True\n",
            "225 activation_63 True\n",
            "226 activation_68 True\n",
            "227 activation_69 True\n",
            "228 mixed7 True\n",
            "229 conv2d_72 True\n",
            "230 batch_normalization_72 True\n",
            "231 activation_72 True\n",
            "232 conv2d_73 True\n",
            "233 batch_normalization_73 True\n",
            "234 activation_73 True\n",
            "235 conv2d_70 True\n",
            "236 conv2d_74 True\n",
            "237 batch_normalization_70 True\n",
            "238 batch_normalization_74 True\n",
            "239 activation_70 True\n",
            "240 activation_74 True\n",
            "241 conv2d_71 True\n",
            "242 conv2d_75 True\n",
            "243 batch_normalization_71 True\n",
            "244 batch_normalization_75 True\n",
            "245 activation_71 True\n",
            "246 activation_75 True\n",
            "247 max_pooling2d_3 True\n",
            "248 mixed8 True\n",
            "249 conv2d_80 True\n",
            "250 batch_normalization_80 True\n",
            "251 activation_80 True\n",
            "252 conv2d_77 True\n",
            "253 conv2d_81 True\n",
            "254 batch_normalization_77 True\n",
            "255 batch_normalization_81 True\n",
            "256 activation_77 True\n",
            "257 activation_81 True\n",
            "258 conv2d_78 True\n",
            "259 conv2d_79 True\n",
            "260 conv2d_82 True\n",
            "261 conv2d_83 True\n",
            "262 average_pooling2d_7 True\n",
            "263 conv2d_76 True\n",
            "264 batch_normalization_78 True\n",
            "265 batch_normalization_79 True\n",
            "266 batch_normalization_82 True\n",
            "267 batch_normalization_83 True\n",
            "268 conv2d_84 True\n",
            "269 batch_normalization_76 True\n",
            "270 activation_78 True\n",
            "271 activation_79 True\n",
            "272 activation_82 True\n",
            "273 activation_83 True\n",
            "274 batch_normalization_84 True\n",
            "275 activation_76 True\n",
            "276 mixed9_0 True\n",
            "277 concatenate True\n",
            "278 activation_84 True\n",
            "279 mixed9 True\n",
            "280 conv2d_89 True\n",
            "281 batch_normalization_89 True\n",
            "282 activation_89 True\n",
            "283 conv2d_86 True\n",
            "284 conv2d_90 True\n",
            "285 batch_normalization_86 True\n",
            "286 batch_normalization_90 True\n",
            "287 activation_86 True\n",
            "288 activation_90 True\n",
            "289 conv2d_87 True\n",
            "290 conv2d_88 True\n",
            "291 conv2d_91 True\n",
            "292 conv2d_92 True\n",
            "293 average_pooling2d_8 True\n",
            "294 conv2d_85 True\n",
            "295 batch_normalization_87 True\n",
            "296 batch_normalization_88 True\n",
            "297 batch_normalization_91 True\n",
            "298 batch_normalization_92 True\n",
            "299 conv2d_93 True\n",
            "300 batch_normalization_85 True\n",
            "301 activation_87 True\n",
            "302 activation_88 True\n",
            "303 activation_91 True\n",
            "304 activation_92 True\n",
            "305 batch_normalization_93 True\n",
            "306 activation_85 True\n",
            "307 mixed9_1 True\n",
            "308 concatenate_1 True\n",
            "309 activation_93 True\n",
            "310 mixed10 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQk0H-DPIm4C",
        "outputId": "5b2b1aa6-d1c9-4064-97a9-256610af98b3"
      },
      "source": [
        "# Freeze first 285 layers\n",
        "for i, layer in enumerate(ft_model.get_layer('inception_v3').layers[:285]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_model.get_layer('inception_v3').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 False\n",
            "1 conv2d False\n",
            "2 batch_normalization False\n",
            "3 activation False\n",
            "4 conv2d_1 False\n",
            "5 batch_normalization_1 False\n",
            "6 activation_1 False\n",
            "7 conv2d_2 False\n",
            "8 batch_normalization_2 False\n",
            "9 activation_2 False\n",
            "10 max_pooling2d False\n",
            "11 conv2d_3 False\n",
            "12 batch_normalization_3 False\n",
            "13 activation_3 False\n",
            "14 conv2d_4 False\n",
            "15 batch_normalization_4 False\n",
            "16 activation_4 False\n",
            "17 max_pooling2d_1 False\n",
            "18 conv2d_8 False\n",
            "19 batch_normalization_8 False\n",
            "20 activation_8 False\n",
            "21 conv2d_6 False\n",
            "22 conv2d_9 False\n",
            "23 batch_normalization_6 False\n",
            "24 batch_normalization_9 False\n",
            "25 activation_6 False\n",
            "26 activation_9 False\n",
            "27 average_pooling2d False\n",
            "28 conv2d_5 False\n",
            "29 conv2d_7 False\n",
            "30 conv2d_10 False\n",
            "31 conv2d_11 False\n",
            "32 batch_normalization_5 False\n",
            "33 batch_normalization_7 False\n",
            "34 batch_normalization_10 False\n",
            "35 batch_normalization_11 False\n",
            "36 activation_5 False\n",
            "37 activation_7 False\n",
            "38 activation_10 False\n",
            "39 activation_11 False\n",
            "40 mixed0 False\n",
            "41 conv2d_15 False\n",
            "42 batch_normalization_15 False\n",
            "43 activation_15 False\n",
            "44 conv2d_13 False\n",
            "45 conv2d_16 False\n",
            "46 batch_normalization_13 False\n",
            "47 batch_normalization_16 False\n",
            "48 activation_13 False\n",
            "49 activation_16 False\n",
            "50 average_pooling2d_1 False\n",
            "51 conv2d_12 False\n",
            "52 conv2d_14 False\n",
            "53 conv2d_17 False\n",
            "54 conv2d_18 False\n",
            "55 batch_normalization_12 False\n",
            "56 batch_normalization_14 False\n",
            "57 batch_normalization_17 False\n",
            "58 batch_normalization_18 False\n",
            "59 activation_12 False\n",
            "60 activation_14 False\n",
            "61 activation_17 False\n",
            "62 activation_18 False\n",
            "63 mixed1 False\n",
            "64 conv2d_22 False\n",
            "65 batch_normalization_22 False\n",
            "66 activation_22 False\n",
            "67 conv2d_20 False\n",
            "68 conv2d_23 False\n",
            "69 batch_normalization_20 False\n",
            "70 batch_normalization_23 False\n",
            "71 activation_20 False\n",
            "72 activation_23 False\n",
            "73 average_pooling2d_2 False\n",
            "74 conv2d_19 False\n",
            "75 conv2d_21 False\n",
            "76 conv2d_24 False\n",
            "77 conv2d_25 False\n",
            "78 batch_normalization_19 False\n",
            "79 batch_normalization_21 False\n",
            "80 batch_normalization_24 False\n",
            "81 batch_normalization_25 False\n",
            "82 activation_19 False\n",
            "83 activation_21 False\n",
            "84 activation_24 False\n",
            "85 activation_25 False\n",
            "86 mixed2 False\n",
            "87 conv2d_27 False\n",
            "88 batch_normalization_27 False\n",
            "89 activation_27 False\n",
            "90 conv2d_28 False\n",
            "91 batch_normalization_28 False\n",
            "92 activation_28 False\n",
            "93 conv2d_26 False\n",
            "94 conv2d_29 False\n",
            "95 batch_normalization_26 False\n",
            "96 batch_normalization_29 False\n",
            "97 activation_26 False\n",
            "98 activation_29 False\n",
            "99 max_pooling2d_2 False\n",
            "100 mixed3 False\n",
            "101 conv2d_34 False\n",
            "102 batch_normalization_34 False\n",
            "103 activation_34 False\n",
            "104 conv2d_35 False\n",
            "105 batch_normalization_35 False\n",
            "106 activation_35 False\n",
            "107 conv2d_31 False\n",
            "108 conv2d_36 False\n",
            "109 batch_normalization_31 False\n",
            "110 batch_normalization_36 False\n",
            "111 activation_31 False\n",
            "112 activation_36 False\n",
            "113 conv2d_32 False\n",
            "114 conv2d_37 False\n",
            "115 batch_normalization_32 False\n",
            "116 batch_normalization_37 False\n",
            "117 activation_32 False\n",
            "118 activation_37 False\n",
            "119 average_pooling2d_3 False\n",
            "120 conv2d_30 False\n",
            "121 conv2d_33 False\n",
            "122 conv2d_38 False\n",
            "123 conv2d_39 False\n",
            "124 batch_normalization_30 False\n",
            "125 batch_normalization_33 False\n",
            "126 batch_normalization_38 False\n",
            "127 batch_normalization_39 False\n",
            "128 activation_30 False\n",
            "129 activation_33 False\n",
            "130 activation_38 False\n",
            "131 activation_39 False\n",
            "132 mixed4 False\n",
            "133 conv2d_44 False\n",
            "134 batch_normalization_44 False\n",
            "135 activation_44 False\n",
            "136 conv2d_45 False\n",
            "137 batch_normalization_45 False\n",
            "138 activation_45 False\n",
            "139 conv2d_41 False\n",
            "140 conv2d_46 False\n",
            "141 batch_normalization_41 False\n",
            "142 batch_normalization_46 False\n",
            "143 activation_41 False\n",
            "144 activation_46 False\n",
            "145 conv2d_42 False\n",
            "146 conv2d_47 False\n",
            "147 batch_normalization_42 False\n",
            "148 batch_normalization_47 False\n",
            "149 activation_42 False\n",
            "150 activation_47 False\n",
            "151 average_pooling2d_4 False\n",
            "152 conv2d_40 False\n",
            "153 conv2d_43 False\n",
            "154 conv2d_48 False\n",
            "155 conv2d_49 False\n",
            "156 batch_normalization_40 False\n",
            "157 batch_normalization_43 False\n",
            "158 batch_normalization_48 False\n",
            "159 batch_normalization_49 False\n",
            "160 activation_40 False\n",
            "161 activation_43 False\n",
            "162 activation_48 False\n",
            "163 activation_49 False\n",
            "164 mixed5 False\n",
            "165 conv2d_54 False\n",
            "166 batch_normalization_54 False\n",
            "167 activation_54 False\n",
            "168 conv2d_55 False\n",
            "169 batch_normalization_55 False\n",
            "170 activation_55 False\n",
            "171 conv2d_51 False\n",
            "172 conv2d_56 False\n",
            "173 batch_normalization_51 False\n",
            "174 batch_normalization_56 False\n",
            "175 activation_51 False\n",
            "176 activation_56 False\n",
            "177 conv2d_52 False\n",
            "178 conv2d_57 False\n",
            "179 batch_normalization_52 False\n",
            "180 batch_normalization_57 False\n",
            "181 activation_52 False\n",
            "182 activation_57 False\n",
            "183 average_pooling2d_5 False\n",
            "184 conv2d_50 False\n",
            "185 conv2d_53 False\n",
            "186 conv2d_58 False\n",
            "187 conv2d_59 False\n",
            "188 batch_normalization_50 False\n",
            "189 batch_normalization_53 False\n",
            "190 batch_normalization_58 False\n",
            "191 batch_normalization_59 False\n",
            "192 activation_50 False\n",
            "193 activation_53 False\n",
            "194 activation_58 False\n",
            "195 activation_59 False\n",
            "196 mixed6 False\n",
            "197 conv2d_64 False\n",
            "198 batch_normalization_64 False\n",
            "199 activation_64 False\n",
            "200 conv2d_65 False\n",
            "201 batch_normalization_65 False\n",
            "202 activation_65 False\n",
            "203 conv2d_61 False\n",
            "204 conv2d_66 False\n",
            "205 batch_normalization_61 False\n",
            "206 batch_normalization_66 False\n",
            "207 activation_61 False\n",
            "208 activation_66 False\n",
            "209 conv2d_62 False\n",
            "210 conv2d_67 False\n",
            "211 batch_normalization_62 False\n",
            "212 batch_normalization_67 False\n",
            "213 activation_62 False\n",
            "214 activation_67 False\n",
            "215 average_pooling2d_6 False\n",
            "216 conv2d_60 False\n",
            "217 conv2d_63 False\n",
            "218 conv2d_68 False\n",
            "219 conv2d_69 False\n",
            "220 batch_normalization_60 False\n",
            "221 batch_normalization_63 False\n",
            "222 batch_normalization_68 False\n",
            "223 batch_normalization_69 False\n",
            "224 activation_60 False\n",
            "225 activation_63 False\n",
            "226 activation_68 False\n",
            "227 activation_69 False\n",
            "228 mixed7 False\n",
            "229 conv2d_72 False\n",
            "230 batch_normalization_72 False\n",
            "231 activation_72 False\n",
            "232 conv2d_73 False\n",
            "233 batch_normalization_73 False\n",
            "234 activation_73 False\n",
            "235 conv2d_70 False\n",
            "236 conv2d_74 False\n",
            "237 batch_normalization_70 False\n",
            "238 batch_normalization_74 False\n",
            "239 activation_70 False\n",
            "240 activation_74 False\n",
            "241 conv2d_71 False\n",
            "242 conv2d_75 False\n",
            "243 batch_normalization_71 False\n",
            "244 batch_normalization_75 False\n",
            "245 activation_71 False\n",
            "246 activation_75 False\n",
            "247 max_pooling2d_3 False\n",
            "248 mixed8 False\n",
            "249 conv2d_80 False\n",
            "250 batch_normalization_80 False\n",
            "251 activation_80 False\n",
            "252 conv2d_77 False\n",
            "253 conv2d_81 False\n",
            "254 batch_normalization_77 False\n",
            "255 batch_normalization_81 False\n",
            "256 activation_77 False\n",
            "257 activation_81 False\n",
            "258 conv2d_78 False\n",
            "259 conv2d_79 False\n",
            "260 conv2d_82 False\n",
            "261 conv2d_83 False\n",
            "262 average_pooling2d_7 False\n",
            "263 conv2d_76 False\n",
            "264 batch_normalization_78 False\n",
            "265 batch_normalization_79 False\n",
            "266 batch_normalization_82 False\n",
            "267 batch_normalization_83 False\n",
            "268 conv2d_84 False\n",
            "269 batch_normalization_76 False\n",
            "270 activation_78 False\n",
            "271 activation_79 False\n",
            "272 activation_82 False\n",
            "273 activation_83 False\n",
            "274 batch_normalization_84 False\n",
            "275 activation_76 False\n",
            "276 mixed9_0 False\n",
            "277 concatenate False\n",
            "278 activation_84 False\n",
            "279 mixed9 False\n",
            "280 conv2d_89 False\n",
            "281 batch_normalization_89 False\n",
            "282 activation_89 False\n",
            "283 conv2d_86 False\n",
            "284 conv2d_90 False\n",
            "285 batch_normalization_86 True\n",
            "286 batch_normalization_90 True\n",
            "287 activation_86 True\n",
            "288 activation_90 True\n",
            "289 conv2d_87 True\n",
            "290 conv2d_88 True\n",
            "291 conv2d_91 True\n",
            "292 conv2d_92 True\n",
            "293 average_pooling2d_8 True\n",
            "294 conv2d_85 True\n",
            "295 batch_normalization_87 True\n",
            "296 batch_normalization_88 True\n",
            "297 batch_normalization_91 True\n",
            "298 batch_normalization_92 True\n",
            "299 conv2d_93 True\n",
            "300 batch_normalization_85 True\n",
            "301 activation_87 True\n",
            "302 activation_88 True\n",
            "303 activation_91 True\n",
            "304 activation_92 True\n",
            "305 batch_normalization_93 True\n",
            "306 activation_85 True\n",
            "307 mixed9_1 True\n",
            "308 concatenate_1 True\n",
            "309 activation_93 True\n",
            "310 mixed10 True\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 6, 6, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                7182      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,859,054\n",
            "Trainable params: 3,877,134\n",
            "Non-trainable params: 18,981,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAshLqPXQcNN",
        "outputId": "61b98732-c4f4-4017-cba9-31e1d2094737"
      },
      "source": [
        "ft_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 6, 6, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                7182      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,859,054\n",
            "Trainable params: 3,877,134\n",
            "Non-trainable params: 18,981,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYQ3G3bUI_5_"
      },
      "source": [
        "# Compile the model\n",
        "ft_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "lrIzW7KWJXjn",
        "outputId": "5d189774-8500-4a25-f1e4-34721f109495"
      },
      "source": [
        "# Fine-tune the model\n",
        "ft_history = ft_model.fit(x=train_dataset,\n",
        "          epochs=30,\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen),\n",
        "          class_weight=class_weights,callbacks = es_callback).history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "444/444 [==============================] - 285s 630ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0403 - val_accuracy: 0.9881\n",
            "Epoch 2/30\n",
            "444/444 [==============================] - 286s 646ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0395 - val_accuracy: 0.9876\n",
            "Epoch 3/30\n",
            "444/444 [==============================] - 286s 646ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0563 - val_accuracy: 0.9850\n",
            "Epoch 4/30\n",
            "444/444 [==============================] - 287s 646ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0386 - val_accuracy: 0.9884\n",
            "Epoch 5/30\n",
            "444/444 [==============================] - 285s 643ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0481 - val_accuracy: 0.9881\n",
            "Epoch 6/30\n",
            " 51/444 [==>...........................] - ETA: 3:40 - loss: 5.5906e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-6f8ee819a2af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           class_weight=class_weights,callbacks = es_callback).history\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8KelEagP2u9",
        "outputId": "4b104f00-c025-4a97-a06e-b49d16723594"
      },
      "source": [
        "ft_model.save('classification_experiments/FineTuningModel')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: classification_experiments/FineTuningModel/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LzHgzen7x9w"
      },
      "source": [
        "## Analysis of the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlHs-IxS71kL"
      },
      "source": [
        "# Plot the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, top_k_accuracy_score, balanced_accuracy_score\n",
        "\n",
        "y_pred = model.predict(test_gen)\n",
        "y_pred_m = np.argmax(y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(test_gen.classes, y_pred_m, normalize='true')\n",
        "b_acc = balanced_accuracy_score(test_gen.classes, y_pred_m)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "im = ax.imshow(cm)\n",
        "ax.set_title(\"Matrice de confusion\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "print('Balanced accuracy = ', b_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}